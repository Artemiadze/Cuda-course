## Nuts and Bolts of the operations

Вот некоторые основные элементы CUDA, которые будут использоваться бесчисленное количество раз в будущем.

### Kernel

Ядро (kernel) — это специальная функция, которая выполняется на вашем GPU (графической карте), а не на CPU. Представьте, что вы даёте инструкции большой команде работников (потоков GPU), которые могут работать одновременно. Ядро обозначается ключевым словом `__global__` и может возвращать только `void`.

### Grid

Сетка (grid) представляет собой весь набор потоков, запускаемых для одного вызова ядра. Это как общее пространство выполнения. Она состоит из блоков потоков.

Когда вы запускаете ядро, вы указываете размеры сетки — это определяет, сколько блоков будет создано. Сетка может быть 1D, 2D или 3D (например, линия, плоскость или куб блоков).

* Пример: При обработке большого изображения каждый блок может обрабатывать свой участок изображения.

### Block

Блок — это группа потоков, которые могут взаимодействовать и быстро обмениваться данными через разделяемую память. Блок также может быть 1D, 2D или 3D.

* Потоки в блоке могут:

  * Делить между собой память
  * Синхронизироваться
  * Работать совместно над задачами

* Пример: При обработке изображения блок может обрабатывать область 16x16 пикселей.

### Threads

Поток — это наименьшая единица исполнения в CUDA. Каждый поток выполняет код ядра независимо. Внутри блока потоки идентифицируются уникальным идентификатором потока. Этот ID позволяет обращаться к нужным данным или выполнять разные действия в зависимости от позиции потока внутри блока.

> У каждого потока есть уникальный ID, чтобы он знал, с какими данными работать.

---

### Understanding CUDA Thread Indexing

В CUDA у каждого потока есть уникальный идентификатор, который можно использовать для определения его позиции в сетке и блоке. Часто используются следующие переменные:

1. **`threadIdx`**:

   * Вектор из 3 компонентов (`threadIdx.x`, `threadIdx.y`, `threadIdx.z`), определяющий позицию потока внутри блока.
   * Пример: Если у вас 1D-блок из 256 потоков, `threadIdx.x` принимает значения от `0` до `255`.

2. **`blockDim`**:

   * Вектор из 3 компонентов (`blockDim.x`, `blockDim.y`, `blockDim.z`), указывающий размеры блока.
   * Пример: Если в блоке 256 потоков по x, то `blockDim.x` равен `256`.

3. **`blockIdx`**:

   * Вектор из 3 компонентов (`blockIdx.x`, `blockIdx.y`, `blockIdx.z`), определяющий позицию блока в сетке.
   * Пример: Если у вас 1D-сетка из 10 блоков, `blockIdx.x` принимает значения от `0` до `9`.

4. **`gridDim`**:

   * Вектор из 3 компонентов (`gridDim.x`, `gridDim.y`, `gridDim.z`), указывающий размеры сетки.
   * Пример: Если в сетке 10 блоков по x, `gridDim.x` будет `10`.

---

### Calculating Global Thread ID

Чтобы вычислить уникальный глобальный идентификатор потока (например, для доступа к элементам массива), можно использовать формулу:

```cpp
int globalThreadId = blockIdx.x * blockDim.x + threadIdx.x;
```

* `blockIdx.x * blockDim.x` даёт начальный индекс текущего блока
* `threadIdx.x` добавляет смещение внутри блока

---

## Helper Types and Functions

#### dim3

* Удобный способ задать размеры в 3D
* Используется для задания размеров сетки и блоков
* Пример:

```cpp
dim3 blockSize(16, 16, 1);  // 16x16x1 потоков в блоке
dim3 gridSize(8, 8, 1);     // 8x8x1 блоков в сетке
```

#### <<<>>>

Используется для настройки и запуска ядер на GPU. Определяет размеры сетки и блока, объём shared memory и поток исполнения. Правильная настройка этих параметров критична для эффективной работы на GPU и получения максимальной производительности.

* Специальные скобки для запуска ядер
* Указывают размеры сетки и блока
* Пример:

```cpp
addNumbers<<<gridSize, blockSize>>>(a, b, result);
```

Здесь `addNumbers` — имя ядра, `gridSize` и `blockSize` — размеры сетки и блока, а `a`, `b`, `result` — аргументы ядра

---

## Memory Management

#### cudaMalloc

* Выделяет память на GPU
* Аналог `malloc`, но для памяти GPU
* Пример:

```cpp
int *device_array;
cudaMalloc(&device_array, size * sizeof(int));
```

#### cudaMemcpy

Может копировать данные:

* с CPU на GPU (host to device)

* с GPU на CPU (device to host)

* с одного участка GPU в другой (device to device — редко)

* Используются флаги: `cudaMemcpyHostToDevice`, `cudaMemcpyDeviceToHost`, `cudaMemcpyDeviceToDevice`

* `cudaFree` освобождает память на устройстве

* Пример:

```cpp
cudaMemcpy(device_array, host_array, size * sizeof(int), cudaMemcpyHostToDevice);
```

#### cudaDeviceSynchronize()

По умолчанию CPU и GPU работают параллельно для максимальной скорости, но иногда нужно заставить CPU подождать завершения работы GPU — для этого используется `cudaDeviceSynchronize()`.

* Полезно, когда нужны результаты до продолжения работы
* Мы будем использовать это при измерении времени
* Пример:

```cpp
kernel<<<gridSize, blockSize>>>(data);
cudaDeviceSynchronize();  // Ждать завершения ядра
printf("Kernel completed!");
```

---

## Some theory on Memory

CUDA предоставляет несколько типов памяти, каждая из которых имеет разную скорость и предназначение:

1. **Global Memory**:

   * Основная память GPU, доступна всем потокам
   * **Самая медленная**, но **самая большая** по объёму
   * Используется для данных, доступных всем потокам
   * Пример: Массивы или большие наборы данных

2. **Shared Memory**:

   * Общая память для всех потоков внутри **одного блока**
   * **Очень быстрая**, но **маленькая**
   * Используется для данных, которыми часто обмениваются потоки блока
   * Пример: Временные переменные или таблицы

3. **Registers**:

   * Самая быстрая память, приватная для каждого **потока**
   * Используется для локальных переменных
   * Ограничена по количеству, использовать с умом
   * Пример: Счётчики циклов или промежуточные вычисления

4. **Constant Memory**:

   * Только для чтения, доступна всем потокам
   * Кэшируется для быстрого доступа
   * Используется для данных, которые не меняются во время выполнения ядра
   * Пример: Константы или параметры настройки

5. **Local Memory**:

   * Используется, когда не хватает регистров
   * **Медленная**, так как размещается в глобальной памяти
   * Лучше избегать
   * Пример: Большие массивы или переменные, не помещающиеся в регистры

---

## Putting It All Together

Вот простой пример, который объединяет эти концепции:

```cpp
// Kernel definition
__global__ void addArrays(int *a, int *b, int *c, int size) {
    // Calculate unique index for this thread
    int index = blockIdx.x * blockDim.x + threadIdx.x;
    
    // Make sure we don't go past array bounds
    if (index < size) {
        c[index] = a[index] + b[index];
    }
}

// In main function:
dim3 blockSize(256);  // 256 threads per block
dim3 gridSize((size + blockSize.x - 1) / blockSize.x);  // Calculate needed blocks
addArrays<<<gridSize, blockSize>>>(d_a, d_b, d_c, size);
```

Этот пример показывает, как потоки организуются для параллельного сложения двух массивов. Каждый поток обрабатывает один элемент, а размеры блоков и сетки гарантируют, что весь массив будет обработан.

